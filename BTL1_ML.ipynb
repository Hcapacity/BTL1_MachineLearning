import numpy as np

# ----- tiện ích -----
def he_init(fan_in, fan_out):
    return np.random.randn(fan_in, fan_out) * np.sqrt(2.0 / fan_in)

def relu(x):
    return np.maximum(0, x)

def relu_grad(x):
    return (x > 0).astype(x.dtype)

def softmax(z):
    z_shift = z - z.max(axis=1, keepdims=True)
    exp_z = np.exp(z_shift)
    return exp_z / exp_z.sum(axis=1, keepdims=True)

def one_hot(y, C):
    Y = np.zeros((y.shape[0], C))
    Y[np.arange(y.shape[0]), y] = 1.0
    return Y

def accuracy(y_true, y_pred):
    return (y_true == y_pred).mean()

# ----- mô hình MLP 1 hidden layer -----
class MLP:
    def __init__(self, d, h, C, lr=1e-2, seed=42, l2=0.0):
        rng = np.random.default_rng(seed)
        self.W1 = rng.normal(0, np.sqrt(2/d), size=(d, h))  # He init
        self.b1 = np.zeros(h)
        self.W2 = rng.normal(0, np.sqrt(2/h), size=(h, C))
        self.b2 = np.zeros(C)
        self.lr = lr
        self.l2 = l2  # hệ số L2 (optional)

    def forward(self, X):
        Z1 = X @ self.W1 + self.b1
        H  = relu(Z1)
        Z2 = H @ self.W2 + self.b2
        Yhat = softmax(Z2)
        cache = (X, Z1, H, Z2, Yhat)
        return Yhat, cache

    def loss(self, Y, Yhat):
        eps = 1e-12
        ce = -np.sum(Y * np.log(Yhat + eps)) / Y.shape[0]
        if self.l2 > 0:
            ce += 0.5 * self.l2 * (np.sum(self.W1**2) + np.sum(self.W2**2))
        return ce

    def backward(self, cache, Y):
        X, Z1, H, Z2, Yhat = cache
        N = X.shape[0]

        G2 = (Yhat - Y) / N
        dW2 = H.T @ G2
        db2 = G2.sum(axis=0)

        GH = G2 @ self.W2.T
        G1 = GH * relu_grad(Z1)
        dW1 = X.T @ G1
        db1 = G1.sum(axis=0)

        if self.l2 > 0:
            dW2 += self.l2 * self.W2
            dW1 += self.l2 * self.W1

        return dW1, db1, dW2, db2

    def step(self, grads):
        dW1, db1, dW2, db2 = grads
        self.W1 -= self.lr * dW1
        self.b1 -= self.lr * db1
        self.W2 -= self.lr * dW2
        self.b2 -= self.lr * db2

    def predict(self, X):
        Yhat, _ = self.forward(X)
        return np.argmax(Yhat, axis=1)

# ----- demo nhanh với dữ liệu giả -----
if __name__ == "__main__":
    np.random.seed(0)
    N, d, C = 400, 10, 3 
    X = np.random.randn(N, d)
    true_W = np.random.randn(d, C)
    scores = X @ true_W + 0.3*np.random.randn(N, C)
    y = np.argmax(scores, axis=1) 
    Y = one_hot(y, C)

    model = MLP(d=d, h=32, C=C, lr=0.05, l2=1e-4)

    for epoch in range(200):
        Yhat, cache = model.forward(X)
        L = model.loss(Y, Yhat)
        grads = model.backward(cache, Y)
        model.step(grads)

        if (epoch+1) % 20 == 0:
            pred = model.predict(X)
            acc = accuracy(y, pred)
            print(f"Epoch {epoch+1:3d} | loss={L:.4f} | acc={acc:.3f}")
